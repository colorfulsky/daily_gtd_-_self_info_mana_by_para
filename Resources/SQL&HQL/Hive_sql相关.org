#+title:Hive SQL 知识学习及应用
#+author: dong chen

记录日常大数据调用过程当中的问题及解决方案，和部分代码样例。

* 增删改查
** 增
针对集团BDP来说，自行创建对应数据集有些孟浪了，基本作为数据临时中转之用。语法基本也使用数据库标准语法
#+begin_src sql
  create table if not EXISTS XXX(
	 ....
	 )
#+end_src

建表的三种方式，可以参照这个链接，创建分区表尤需谨慎
1. [[https://blog.csdn.net/matrix_google/article/details/84633267][hive建表的三种方式]]
2. 从分区表引用数据并加以覆写，参照下述代码：
#+begin_src sql
  -- Creating partitioned table as select is not supported. You can do it in two steps:

  --create table my_table like dlk.big_table; This will create table with the same schema.

  -- Load data.

  set hive.exec.dynamic.partition=true;
  set hive.exec.dynamic.partition.mode=nonstrict;

  insert overwrite table my_table partition (day, month, year) 
  select * from dlk.big_table;
#+end_src

** 删改
+在集团数据库层面应用很少，按下不表，遇到对应场景，信息对应补充。+
在拥有dm.sxcp数据库读写权限之后，表格更新、删改形成新的任务，随后逐步更新内容。

** *查*
*** 基础操作
*** 链接增强
**** 无关键字两表链接
     #+begin_src sql
       -- 笛卡尔外联，或者多表无条件连接
       select * from table_1 join table_2 join table_3
     #+end_src
**** 不等值链接
     #+begin_src sql
       select * from table1 join table2 on (true) where judging clauses
       --在where子句中通过条件实现非等值链接
     #+end_src
**** 链接理论加强
***** 左链接理解拓展
三种情况下左联不同的结果
| 情景   | 效果                     | 备注            |
|--------+--------------------------+-----------------|
| 一对一 | 以左栏为充分条件进行拓展 | n:m -> n:n      |
| 一对多 | 所有满足条件的行单独成行 | n:m(t) -> n*t:m |
| 多对多 | 以一对多的效果做复合     | -               |

*** 单层条件语句和聚合条件增强
*** 行操作与计算字段（单体函数）
**** 计算字段1to1
1. 日期函数
日常增量更新
#+begin_src sql
  -- 日常处理过程中，逐个添加内容，主要标记边际拓展的内容

  select from_unixstamp(unixstamp('20210413','yyyyMMdd'),'yyyy-MM-dd') -- 日期格式转换

  select weekofyear('yyyyMMdd') -- 给出日期年内周次
#+end_src
2. 文本函数
3. 代数运算
4.自定义函数(hive sql udf)
**** 计算字段2to2
1. 按字段汇集
#+begin_src sql
  select * from exp_table
  where some conditions
  partition by column_name
#+end_src
2. 序列函数or窗口函数
*窗口函数*
序列函数可以实现局部数据空间内的-- 运算多对一，结果一对一的效果，且不依赖于数据的强汇总。子句出现在select的宾语当中，通过src_sql{over} 做关联。涉及到的关键字如下：
| 关键字                        | 功能                                                                |
|-------------------------------+---------------------------------------------------------------------|
| over                          | 充作连接字，关联局部聚合和对应约束语句                              |
| partition by                  | 依照指定字段对条目进行集合，如使得createtime中月份为3月的聚合在一起 |
| rows between x and y          | 在聚集语句当中，依照行段相对位置筛选对应范围值，配合下述字段        |
| preceding                     | 向前计算                                                            |
| following                     | 向后计算                                                            |
| current row                   | 当前行                                                              |
| unbounded following/preceding | 前序到头或者后序到尾                                                          |
#+begin_src sql
  select 
     cookieid, 
     createtime, 
     pv, 
     sum(pv) over (partition by cookieid order by createtime rows between unbounded preceding and current row) as pv1, 
     sum(pv) over (partition by cookieid order by createtime) as pv2, 
     sum(pv) over (partition by cookieid) as pv3, 
     sum(pv) over (partition by cookieid order by createtime rows between 3 preceding and current row) as pv4, 
     sum(pv) over (partition by cookieid order by createtime rows between 3 preceding and 1 following) as pv5, 
     sum(pv) over (partition by cookieid order by createtime rows between current row and unbounded following) as pv6 
  from cookie1;
#+end_src

*分片& row_number*
实现非聚合情况下，数字的分片行数及分片标记。
| 关键字     | 功能                                                                                                                      |
|------------+---------------------------------------------------------------------------------------------------------------------------|
| NTILE      | 根据NTILEN(N) 中N的具体值，将分片值进行切割及标记，如：n=3，则将数据按照某种排序规则，对前1/3标记1,1/3-2/3标记2，以此类推 |
| ROW_NUMBER | 给出分片内既有排序的行数，数字从1开始，通常会搭配上个段落中的rows between 一起使用                                                              |
可以参照下文示例，查看分片功能。
#+begin_src sql
  -- 1 把记录按价格顺序拆分成10片
  drop table if exists test_dp_price_rk;
  create table test_dp_price_rk
  as
  select
   id,
   price,
   NTILE(10) OVER (order by price desc) as rn
  from test_dp_price;

  -- 2 按片取30%和70%，分别计算平均值
  select
    new_rn,
    max(case when new_rn=1 then 'avg_price_first_30%' when new_rn=2 then 'avg_price_last_70%' end) as avg_price_name,
    avg(price) avg_price
  from 
  (
    select 
      id,
      price,
      rn,
      case when rn in (1,2,3) then 1 else 2 end as new_rn
    from test_dp_price_rk
  )a
  group by new_rn;
#+end_src

*组内排序&分位值获取*
实现分片组内排序，并实现组内分位值的重要功能。
| 关键字       | 功能                                             |
| rank         | 实现组内的排序，同样数值除开第一个字段外，会留空 |
| DENSE_RANK   | 实现组内排序，同样数值使用同样编号，不留空       |
| cume_dist    | 实现组内小于等于当前值的行数/组内总行数          |
| percent_rank | 实现组内（当前行rank值-1）/（分组内总行数-1）                      |

#+begin_src sql
  -- 排序
  select
    cookieid,
    createtime,
    pv,
    rank() over (partition by cookieid order by pv desc) as rn1,
    dense_rank() over (partition by cookieid order by pv desc) as rn2,
    row_number() over (partition by cookieid order by pv desc) as rn3
  from cookie.cookie2 
  where cookieid='cookie1';

  -- 累计比例
  select 
    dept,
    userid,
    sal,
    cume_dist() over (order by sal) as rn1,
    cume_dist() over (partition by dept order by sal) as rn2
  from cookie.cookie3;

  -- 分位值排序
#+end_src
**** 条件语句
1、函数功能
主要是 ==case== 和 ==if== 语句。
     #+begin_src sql
       -- 主要是if 和 case 语句

       select if(true or false,choice a,choice b);

       select case key-word when clause1 then res1 when ... then ... else .. end --可以嵌套使用

       ----------------------**-------------------------
       -- 可以搭配在group by z子句中使用，可略去一层嵌套,case从句示例如下，if语句同样

       select case key1 when sit1 then res1 else res2
       from table1
       where ....
       group by (case key1 when sit1 then res1 else res2)

     #+end_src
2、语法&用途
| 字段                    | 用途                                         |
|-------------------------+----------------------------------------------|
| case when then else end | 多重条件判断，可以出现在 *group by* 子句当中 |
| if                      | 条件判断，可以出现在 *group by* 子句当中                   |
**** 行列转换
行列转换操作，实现src_python{import pandas as pd }及src_python{df.stack() df.unstack()}中对应函数功能，拓展了对于SQL数据操纵的理解。需要注意的是，hive SQL不太符合RDB范式要求。
***** 前置知识
#+begin_quote
explode(a) - separates the elements of array a into multiple rows, or the elements of a map into multiple rows and columns
    可以将数组炸开成多行，或者将map炸开成多行多列，是Hive内置的UDTF

split(str, regex) - Splits str around occurances that match regex
    按照正则规则去切割字符串
    
collect_list(x) - Returns a list of objects with duplicates
    返回不去重的集合
    
collect_set(x) - Returns a set of objects with duplicate elements eliminated
    返回一个去重的集合

concat_ws(separator, [string | array(string)]+) - returns the concatenation of the strings separated by the separator
    返回一个特定分隔符的拼接字符串

max(expr) - Returns the maximum value of expr
    返回表达式的最大值
#+end_quote
一般情况下，可以使用 ==desc function explode== 查看函数描述。
***** 数据案例
- 生成数据表
      #+begin_src sql
	-- 生成表1
	create table school_final_test as
	select 'jack' as name, 'english' as subject, 70 as score union all
	select 'jack' as name, 'math' as subject, 80 as score union all
	select 'jack' as name, 'chinese' as subject, 90 as score union all
	select 'tim' as name, 'english' as subject, 10 as score union all
	select 'tim' as name, 'math' as subject, 20 as score union all
	select 'tim' as name, 'chinese' as subject, 30 as score;

	-- 生成表2
	create table school_final_test1 as
	select 'jack' as name, 70 as english,80 as math, 90 as chinese union all
	select 'tim' as name, 10 as english,20 as math, 30 as chinese;
      #+end_src
- 源表形式
表1：
| name | subject | score |
|------+---------+-------|
| jack | english |    70 |
| jack | math    |    80 |
| jack | chinese |    90 |
| tim  | english |    10 |
| tim  | math    |    20 |
| tim  | chinese |    30 |

表2：
| name | english | math | chinese |
| jack |      70 |   80 |      90 |
| tim  |      10 |   20 |      30 |

****** Question 1
输入：表1  输出：表2
#+begin_src sql
  -- 使用 case when 及 group by 、max 实现标定行的转置筛选
  select name,
  max(case subject when 'english' then score else 0 end) as english,
  max(case subject when 'math' then score else 0 end) as math,
  max(case subject when 'chinese' then score else 0 end) as chinese
  from school_final_test
  group by name;
#+end_src
****** Qusetion 2
输入：表1  输出：如下
| name | scores                        |
|------+-------------------------------|
| jack | english:70,math:80,chinese:90 |
| tim  | english:10,math:20,chinese:30 |
#+begin_src sql
  --group by + collect_list + concat_ws 协同使用
  select name,concat_ws(',',
      collect_list(
	  concat_ws(':',subject,cast(score as string))
	  )
      ) as scores
  from school_final_test
  group by name;
#+end_src
****** Question 3
输入：表2  输出：如下
| name | subject | score |
|------+---------+-------|
| jack | english |    70 |
| jack | math    |    80 |
| jack | chinese |    90 |
| tim  | english |    10 |
| tim  | math    |    20 |
| tim  | chinese |    30 |

#+begin_src sql
  -- 使用常量值生成固定序列，如下述'english'\'math'等，随后使用 union all 合并，实际上等价于 merge(axis=1)
  select name,'english' as subject,english as score from school_final_test1 
  union all 
  select name,'math' as subject,math as score from school_final_test1 
  union all 
  select name,'chinese' as subject,chinese as score from school_final_test1;
#+end_src

****** Question 4
输入：
| name | scores                        |
|------+-------------------------------|
| jack | english:70,math:80,chinese:90 |
| tim  | english:10,math:20,chinese:30 |
输出：
| name | scores     |
|------+------------|
| jack | english:70 |
| jack | math:80    |
| jack | chinese:90 |
| tim  | english:10 |
| tim  | math:20    |
| tim  | chinese:30 |

#+begin_src sql
  -- split + explode语法
  -- Lateral View是一个连接用户自定义函数(UDFs)的连接词，可以有多个;如果炸裂的列中有null值但是需要显示可以在view后面加outer，类似表的左外连接;

  -- 其中table1表示开窗得到的新表别名，必须写但可不使用(不使用时必须保证没有重复的列名)
  select name,table1.scores as scores
  from school_final_test2
  lateral view explode(split(scores,',')) table1 as scores;
#+end_src


* 行列转换与映射专题
主要记录行列转换功能实现及复杂数据结构使用。
#+begin_src sql
  -----------------hive 行列转换测试用例


  drop table if exists default.jj_tmp1_ts;--删除可能的残存表
  create table default.jj_tmp1_ts (a string,b string,c string) stored as parquet; --建立测试表1
  insert into table default.jj_tmp1_ts  values ('1','dong','12'),('2','xi','14'),('3','nan','15'); --插入表1测试数据
  insert into table default.jj_tmp1_ts  values ('','ti',''); --引入数据null值
  select * from default.jj_tmp1_ts limit 10;


  --------------------------------------------------------------------------------------
  --测试基于字段的行/列复杂数据形式拼接（array\dict），源数据表保留，生成一个中间用表
  --exm1 行array拼接,基于concat_ws,缺点是生成的为字符串不具备下步操作潜力
  create table default.jj_tmp1_ts_tmp as 
  select   t.*,concat_ws(',',a,b,c) cnc_row from default.jj_tmp1_ts t;

  select * from default.jj_tmp1_ts_tmp limit 10;
  desc default.jj_tmp1_ts_tmp;

  --exm1.2 使用array关键字进项拼接
  drop table if exists default.jj_tmp1_ts_tmp;
  create table default.jj_tmp1_ts_tmp as 
  select   t.*,concat_ws(',',a,b,c) cnc_row,array(a,b,c) arr_row from default.jj_tmp1_ts t;

  --实现列转行，单字段
  create table default.jj_tmp1_ts_tmp_fn1 as 
  select t.*,g.exp_ad from default.jj_tmp1_ts_tmp t lateral view explode(arr_row) g as exp_ad;
  select * from default.jj_tmp1_ts_tmp_fn1 limit 10;
  desc default.jj_tmp1_ts_tmp_fn1;

  --实现列转行，多字段
  create table default.jj_tmp1_ts_tmp_fn2 as 
  select t.*,g1.exp_ad1,g2.exp_ad2 from default.jj_tmp1_ts_tmp t 
      lateral view explode(split(concat_ws(',',a,b),',')) g1 as exp_ad1  --生成拼接字段1
      lateral view explode(arr_row) g2 as exp_ad2;  --生成拼接字段2
  select * from default.jj_tmp1_ts_tmp_fn2 limit 100; --两个拼接字段结果为笛卡尔乘积形式
  desc default.jj_tmp1_ts_tmp_fn2;


  --------------------------------------------------------------------------------------------------------------------------
  --------------------------------------------------------------------------------------------------------------------------
  --exm2 列array拼接，基于group by 和 collect_list 进行操作，尝试使用union进行拼接会因为新生成字段数据类型和原值不同而失败;
  drop table if exists default.jj_tmp1_ts_tmp2;
  create table if not exists default.jj_tmp1_ts_tmp2 as
  select collect_list(a) a,collect_list(b) b,collect_list(c) c from default.jj_tmp1_ts_tmp group by 1;
  select * from default.jj_tmp1_ts_tmp2 limit 10;
  desc default.jj_tmp1_ts_tmp2;

  --exm2.1 实现列转列 inline 方式，但会发现inline无法用于array格式
  -- select * from default.jj_tmp1_ts_tmp2 t lateral view inline(a) g;

  --exm2.2 根据实验结果，array会因为和inline无法搭配而失败，改用struct方式,基于列值拼接拆解
  drop table if exists default.jj_tmp1_ts_tmp3;
  create table if not exists default.jj_tmp1_ts_tmp3 as
  select t.*,named_struct('a',a,'b',b,'c',c,'arr_row',arr_row) struct_a,named_struct('a',a,'b',b) struct_b from default.jj_tmp1_ts_tmp t;
  select * from default.jj_tmp1_ts_tmp3 limit 10;
  desc default.jj_tmp1_ts_tmp3;

  -- 实现横向列转列，基于inline制表函数
  select t.*,g.a1,g.b1,g.c1 from default.jj_tmp1_ts_tmp3 t lateral view inline(array(t.struct_a)) g as a1,b1,c1,other;

  -- 多字段维度
  select t.*,g2.tt1,g1.other from default.jj_tmp1_ts_tmp3 t 
      lateral view inline(array(t.struct_a)) g1 as a1,b1,c1,other
      lateral view inline(array(t.struct_b)) g2 as tt1,tt2;


  --exm2.3 参照2.1使用行归集，然后进行拆分为列
  drop table if exists default.jj_tmp1_ts_tmp2;
  create table if not exists default.jj_tmp1_ts_tmp2 as
  select named_struct('a',collect_list(a)) struct_a,collect_list(b) b,named_struct('c',collect_list(c)) struct_c from default.jj_tmp1_ts_tmp group by 1;
  select * from default.jj_tmp1_ts_tmp2 limit 10;
  desc default.jj_tmp1_ts_tmp2;

  --列值维度的行inline不存在行列位置处理的问题，尝试制造下冲突
  insert into table default.jj_tmp1_ts_tmp2 select named_struct('a',array('hi')),array('b'),named_struct('c',array('hello'));

  --发现：由于列值都有一致的格式要求，所以inline炸裂的效果可以值之间是一对一的关系，不存在出现笛卡尔乘积的情况
  select t.*,g.aa from default.jj_tmp1_ts_tmp2 t lateral view inline(array(t.struct_a)) g as aa;

  -----------------------------------------------------------------------------------------
  --exm 3 转置问题
  --区别于一般的矩阵转置，由于hive值存储的方式（列数据具备相同单值限制--数值类型、格式等；行数据为一系列不同属性值），所以转置操作具备方向性，另外hive里面没有类似Dataframe数据帧的index概念，可都视为列值；

  ----------------------------------------------------------------------------------------------------------------------------------
  create table default.jj_tmp1_ts2 (a string,b string,ex string) stored as parquet; --建立测试表2
  insert into table default.jj_tmp1_ts2  values ('1','dong','ta'),('','xi','14'),('3','','15'),('11','',''); --插入表2测试数据
  select * from  default.jj_tmp1_ts2 limit 10;

  create table if not exists default.jj_tmp1_ts2_ts_fn as
  select
      m.id,
      n.col1,
      n.col2,
      n.col3,
      n.col4

  from     
      (select
	  id,
	  collect_list(bb) ts
      from (
	      select
		  g.id,
		  g.bb 
		  from (
			  select map('a',a,'b',b,'ex',ex) cc from default.jj_tmp1_ts2  --生成一维表中间结构压缩数据，其中map部分也可以视为部分固定范式
		      ) t 
	      lateral view explode(t.cc) g as id,bb                    --按照ket,value炸裂
	  ) f                                                          -- 生成行列中间值
      group by id                                                      --固定范式，按照id 汇总
      ) m 
      lateral view inline(array(struct(ts[0],ts[1],ts[2],ts[3]))) n as col1,col2,col3,col4 -- 固定范式，将中间结果拼接为array<struct{}>结构，使用inline炸裂，并命名新的列值
  ;

  select * from default.jj_tmp1_ts2_ts_fn limit 10; --完美实现

  --说明：转置为受限操作，最好保证所有字段为统一数字格式，统一为字符串或者其他

  -------------------------------------------------------------------------------------------------------------------
  --exm 4 数据层叠 --stack --似乎和Python的层级堆叠并不是一个意思

  SELECT stack(4, 'b', 'y', 'b2','b3','b4') as (b,c);
#+end_src
